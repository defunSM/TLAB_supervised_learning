{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the columns on the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at how many transactions are fraud\n",
    "df['isFraud'].value_counts()\n",
    "\n",
    "# need this later when undersampling\n",
    "NUMBER_OF_FRAUD_TRANSACTIONS = len(df[df['isFraud']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.drop(['step', 'nameDest', 'nameOrig', 'isFlaggedFraud'], axis=1)\n",
    "clean_df.to_csv('../data/processed/model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns \n",
    "\n",
    "Drop 3 columns: step, nameDest and nameOrig since we do not need the names of the transaction columns for training our model. Another thing we will have to do is rebalance our dataset so that majority of our data is non-fraudlent otherwise the model might just label everything as not fraudulent and still have a high accuracy.\n",
    "\n",
    "Additionally the model does not need the naive model column isFlaggedFraud that can be removed.\n",
    "\n",
    "## Rebalance\n",
    "There are two different approaches we acn take to rebalanced the dataset:\n",
    "\n",
    "Oversampling or undersampling each with different advantages or disadvantage. We will go with undersampling to avoid overfitting our model this will mean we will be removing some of our non-fraudlent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud\n",
      "1    8213\n",
      "0    8213\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# only the fraudulent transactions\n",
    "df_fraud = df[df['isFraud']==0]\n",
    "\n",
    "# undersample the nonfraud transactions\n",
    "df_undersampled_nonfraud = resample(df_fraud, \n",
    "                                    replace=False,\n",
    "                                    n_samples=NUMBER_OF_FRAUD_TRANSACTIONS,\n",
    "                                    random_state=42)\n",
    "\n",
    "# combine both nonfraud and fraud transactions\n",
    "df_rebalanced = pd.concat([df[df['isFraud']==1], df_undersampled_nonfraud])\n",
    "\n",
    "# Check to see the dataset has been rebalanced\n",
    "print(df_rebalanced['isFraud'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rebalanced dataset\n",
    "\n",
    "df_rebalanced.to_csv('../data/processed/balanced_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
